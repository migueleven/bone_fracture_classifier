{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf53bc67-c089-4d7f-bdaa-58aead502abb",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f010931f-2d7a-4bfc-91cb-3ca05a68c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 🌐 Computer Vision\n",
    "import torch\n",
    "from torch import nn # Neural neutwork components\n",
    "from torch.utils.data import DataLoader # For batching and loading the data\n",
    "from torchvision import datasets # To access FashionMNIST\n",
    "from torchvision.transforms import ToTensor # Convert PIL images to tensors\n",
    "\n",
    "# 🕒 Utilities\n",
    "from timeit import default_timer as timer # Training time duration\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# 📊 Visualization and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18a423-fe1f-445e-9d78-90300ec352b9",
   "metadata": {},
   "source": [
    "## Transform data and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db1e8b52-6e42-4881-9793-0f098047b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_data_transforms(num_channels=1):\n",
    "    \"\"\"\n",
    "    Devuelve las transformaciones de datos para imágenes con un número definido de canales.\n",
    "    \n",
    "    Args:\n",
    "        num_channels (int): Número de canales de salida (1 para escala de grises, 3 para RGB).\n",
    "        \n",
    "    Returns:\n",
    "        data_transforms (torchvision.transforms.Compose): Transformaciones aplicadas a las imágenes.\n",
    "    \"\"\"\n",
    "    grayscale_transform = transforms.Grayscale(num_output_channels=num_channels)\n",
    "    normalization = ([0.485], [0.229])\n",
    "    \n",
    "    data_transforms = transforms.Compose([\n",
    "        grayscale_transform,\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*normalization)\n",
    "    ])\n",
    "    return data_transforms\n",
    "\n",
    "\n",
    "def get_dataloaders(data_dir, batch_size, num_channels, transform=None):\n",
    "    \"\"\"\n",
    "    Carga los datasets y devuelve los DataLoaders para entrenamiento y prueba.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Ruta al directorio que contiene los datos.\n",
    "        batch_size (int): Tamaño del batch.\n",
    "        transform (torchvision.transforms.Compose, optional): Transformaciones para las imágenes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: DataLoader de entrenamiento, DataLoader de prueba y nombres de las clases.\n",
    "    \"\"\"\n",
    "    if transform is None:\n",
    "        transform = get_data_transforms(num_channels)  # Llamada a la función para obtener las transformaciones por defecto\n",
    "    \n",
    "    train_data = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=transform)\n",
    "    test_data = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=transform)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    class_names = train_data.classes\n",
    "    \n",
    "    return train_data, test_data, train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64629837-7c79-4661-b32f-df5f1fcf95d4",
   "metadata": {},
   "source": [
    "## Train and Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "157bffa6-02d5-49f1-b059-68a3f434c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data_loader, loss_fn, optimizer, accuracy_metric, device=device):\n",
    "    scaler = torch.amp.GradScaler(\"cuda\")\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        \n",
    "        y = y.unsqueeze(1).float()  # Asegurar que las etiquetas tengan tamaño [batch_size, 1]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast(device_type=\"cuda\"):  # Mixed Precision\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        preds = (torch.sigmoid(y_pred) > 0.5).int()  # Convertir logits a predicciones binarias\n",
    "        train_acc += accuracy_metric(preds, y.int())\n",
    "\n",
    "    return train_loss / len(data_loader), train_acc.item() / len(data_loader)\n",
    "\n",
    "\n",
    "\n",
    "def test_step(model, data_loader, loss_fn, accuracy_metric, device=device):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y = y.unsqueeze(1).float()  # Asegurar que las etiquetas tengan tamaño [batch_size, 1]\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):  # Mixed Precision\n",
    "                y_pred = model(X)\n",
    "                loss = loss_fn(y_pred, y)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            preds = (torch.sigmoid(y_pred) > 0.5).int()  # Convertir logits a predicciones binarias\n",
    "            test_acc += accuracy_metric(preds, y.int())\n",
    "\n",
    "    return test_loss / len(data_loader), test_acc.item() / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee494f-4e76-4832-b5ec-392755814c7b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44adec32-87fc-4ef5-8912-1cdec7a57a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, test_data, test_dataloader, class_names, device):\n",
    "    \"\"\"\n",
    "    Visualiza predicciones de un modelo en muestras aleatorias del conjunto de datos de prueba.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo entrenado.\n",
    "        test_data (torch.utils.data.Dataset): Dataset de prueba.\n",
    "        test_dataloader (torch.utils.data.DataLoader): DataLoader del dataset de prueba.\n",
    "        class_names (list): Lista con los nombres de las clases.\n",
    "        device (torch.device): Dispositivo donde está el modelo (CPU o GPU).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred_tensor = torch.cat([model(X.to(device)).argmax(dim=1).cpu() for X, _ in test_dataloader])\n",
    "\n",
    "    # Seleccionar 16 muestras aleatorias\n",
    "    test_samples = random.sample(list(test_data), k=16)\n",
    "    test_labels = [label for _, label in test_samples]\n",
    "\n",
    "    # Predicciones para cada muestra\n",
    "    pred_probs = [model(torch.unsqueeze(sample, dim=0).to(device)).softmax(dim=1).cpu() for sample, _ in test_samples]\n",
    "    pred_classes = [prob.argmax() for prob in pred_probs]\n",
    "\n",
    "    # Visualización\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i, (sample, label) in enumerate(test_samples):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(sample[0], cmap=\"gray\")\n",
    "        pred_label = class_names[pred_classes[i]]\n",
    "        truth_label = class_names[label]\n",
    "        plt.title(f\"Pred: {pred_label}\\nTruth: {truth_label}\", fontsize=10,\n",
    "                  color=\"g\" if pred_label == truth_label else \"r\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
